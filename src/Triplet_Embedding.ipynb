{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Triplet Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generating embeddings of the triplets we use Sentence-BERT, which is specifically designed and trained to derive dense vector representations for sentences and paragraphs. Unlike BERT, which outputs one vector for each token in the input, SBERT outputs a single fixed-size vector for an entire text input, making it suitable for semantic similarity tasks and other scenarios where sentence-level representations are required. We used the following template to  obtain a joint representation of hero, villain and victim:\n",
    "\n",
    "```text\n",
    "In this article [HERO] is portrayed as a hero, [VILLAIN] is portrayed as a villain, and [VICTIM] is portrayed as a victim.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/mediacloud/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessing import *\n",
    "from utils.accelerators import *\n",
    "from utils.multithreading import *\n",
    "from utils.database import *\n",
    "from utils.files import *\n",
    "from datasets import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credentials are sourced from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, db = getConnection(use_dotenv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetches a limited number of articles from the database that haven't been processed yet, \n",
    "returning specified fields like url, title, and parsing result text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"v2_sampled_articles\"\n",
    "fields = {\"url\": 1, \"title\": 1, \"parsing_result.text\": 1, \"processing_result\": 1}\n",
    "query = {\n",
    "    \"denoising_result\": {\"$exists\": True},\n",
    "    \"parsing_result.text_length\": {\"$lt\": 10000},\n",
    "    #\"sentence_embedding_result\": {\"$exists\": False},\n",
    "    #\"initial_subsample\": False\n",
    "}\n",
    "articles = fetchArticleTexts(db, 50, 0, fields, query, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: UK’s ‘Sunday Times’ Pulls Transphobic Editorial by British TV Host Jeremy Clarkson After Outrage\n",
      "Text: Towleroad Gay News Gay Blog Towleroad: More than gay news | gay men Michael Fitzgerald January 25, 2016 Leave a Comment   Former Top Gear presenter Jeremy Clarkson has come under fire for his offensive remarks aimed at transgender people. In a newspaper column titled “Transgender issues are driving me nuts” which has since been taken offline, Clarkson wrote that trans people are “only really to be found on the internet or in the seedier bits of Bangkok” and are “nothing more than the punchline in a stag night anecdote.” Writing in the Sunday Times, he added that parents of transgender children should not “indulge this whim” and that after applying “a bit of make-up,” incarcerated trans women “spend the rest of their lives being a lesbian” living “every man's dream.” jeremy clarkson is so disgusting. he's a cis man who knows nothing about trans struggles. pic.twitter.com/VCDkbs8NI3 — gem (@vegbby) January 24, 2016  Last November, British lawmakers announced plans to reexamine policies on transgender prisoners following the death of inmate Vicky Thompson in a male prison. (Image via Facebook) Topics: Film/TV/Stream, Living | Loving More Posts About: Jeremy Clarkson, Television, Top Gear, Transgender  Copyright © 2023 · Log in\n",
      "Processing Result: {'hero': [], 'villain': ['Jeremy Clarkson'], 'victim': ['Transgender people}']}\n"
     ]
    }
   ],
   "source": [
    "example_article = random.choice(articles)\n",
    "title = example_article.get(\"title\")\n",
    "text = example_article.get(\"parsing_result\").get(\"text\")\n",
    "print(f\"Title: {title}\\nText: {text}\")\n",
    "print(f\"Processing Result: {example_article.get('processing_result')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Processes the 'parsing_result' of each article to clean the text, and filters out articles \n",
    "that lack a 'title' or 'parsing_result'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning articles: 100%|██████████| 50/50 [00:00<00:00, 1623.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Basic text cleaning, e.g. removing newlines, tabs, etc.\n",
    "articles = cleanArticles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 50\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles with no title or no parsing result \n",
    "articles = [article for article in articles if article.get(\n",
    "    \"title\", \"\") and article.get(\"parsing_result\", \"\")]\n",
    "\n",
    "print(\"Number of articles:\", len(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the given data to a JSON file for optional visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportAsJSON(\"../data/input/articles.json\",  articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HF Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert article IDs to strings and transform a list of articles into a dataset with fields: id, title, url, and text extracted from parsing results. The HuggingFace `datasets` library provides several key advantages over plain JSON files:\n",
    "\n",
    "- **Efficiency**: The datasets are memory-mapped, allowing you to work with data that's larger than your available RAM without loading the entire dataset into memory. \n",
    "- **Speed**: Datasets in the HuggingFace format (which is Arrow-based) can be loaded faster than large JSON files, facilitating quicker data operations.\n",
    "- **Columnar Storage**: By using Apache Arrow for storage, HuggingFace datasets benefit from a columnar format that ensures more efficient serialization and deserialization compared to row-based storage, such as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 50\n",
      "Column names: ['_id', 'title', 'url', 'text', 'hero', 'villain', 'victim']\n",
      "Features (schema): {'_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'hero': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'villain': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'victim': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"_id\", \"title\", \"url\", \"parsing_result.text\", \"processing_result.hero\", \"processing_result.villain\", \"processing_result.victim\"]\n",
    "articles = convertListToDataset(articles, column_names)\n",
    "describeDataset(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Article Text:  January 19, 2016 at 10:46 am EST By Taegan Goddard 25 Comments Former Defense Secretary Robert Gate\n",
      "Example Article Hero: ['Robert Gates']\n",
      "Example Article Villain: []\n",
      "Example Article Victim: ['Barack Obama']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example Article Text:\", articles[42][\"text\"][:100])\n",
    "print(\"Example Article Hero:\", articles[42][\"hero\"])\n",
    "print(\"Example Article Villain:\", articles[42][\"villain\"])\n",
    "print(\"Example Article Victim:\", articles[42][\"victim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 3634.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "articles.save_to_disk('../data/input/articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from multiprocessing import Pool\n",
    "from utils.preprocessing import *\n",
    "from utils.database import *\n",
    "from utils.files import *\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code `os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"` disables parallel tokenization in HuggingFace's libraries. It's a way to suppress warnings and prevent potential issues tied to multi-core tokenization.\n",
    "See: https://stackoverflow.com/questions/62691279/how-to-disable-tokenizers-parallelism-true-false-warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 50\n",
      "Column names: ['_id', 'title', 'url', 'text', 'hero', 'villain', 'victim']\n",
      "Features (schema): {'_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'hero': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'villain': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'victim': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "articles = load_from_disk('../data/input/articles')\n",
    "describeDataset(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Prompt Template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this article Batman is portrayed as a hero, Joker is portrayed as a villain, and Robin is portrayed as a victim.\n"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"In this article {hero} is portrayed as a hero, {villain} is portrayed as a villain, and {victim} is portrayed as a victim.\"\n",
    "\n",
    "# Test the template with a dummy text\n",
    "print(PROMPT_TEMPLATE.format(hero='Batman', villain='Joker', victim='Robin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article, distinct prompts identify 'hero', 'villain', and 'victim'. If an article exceeds the model's input size, it's divided into chunks, generating additional prompts. It seems that one article results in about 10 to 12 prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '64d8eb39516b2658722931a5',\n",
       " 'title': 'Gates Says Obama Has Too Many &#8216;Yes Men&#8217;',\n",
       " 'url': 'https://politicalwire.com/2016/01/19/gates-says-obama-has-too-many-yes-men/',\n",
       " 'text': \" January 19, 2016 at 10:46 am EST By Taegan Goddard 25 Comments Former Defense Secretary Robert Gates suggested on MSNBC that President Obama has “centralized power and operational activities of the government in the White House to a degree that I think is unparalleled.” He added: “I don’t see the kind of strong people around the President who will push back on him. I will give him credit. I pushed back on him a lot and he never shut me down. He never told me to be quiet or refused to see me or anything like that. But I don’t see people around him like that now. “ Filed Under: Governing, White House Tagged With: Barack Obama, Robert Gates Donald Trump said on Truth Social that his lawyers would prefer that he didn’t have a Monday new conference to unveil his “irrefutable” evidence of fraud in the 2020 Georgia… “The current thinking among Donald Trump’s campaign advisers and those close to the former president is that he is not planning on participating in next week’s Republican presidential primary debate… “The U.S. intelligence community assesses that Ukraine’s counteroffensive will fail to reach the key southeastern city of Melitopol, a finding that, should it prove correct, would mean Kyiv won’t fulfill… “Lawyers for former President Donald Trump asked a judge on Thursday to reject the government’s proposal to take Mr. Trump to trial in early January on charges of seeking to… “North Korea’s successful test launch on July 12 of a nuclear-capable intercontinental ballistic missile equipped to penetrate U.S. missile defenses is likely the result of technical cooperation sourced to Russia,”… “We have been very lean and mean… we certainly don’t want to peak too soon.” — Miami Mayor Francis Suarez, on NBC News, on his apparent lack of any presidential… CNN: “The 98-page document alleges the 30 unindicted co-conspirators, who are not named, ‘constituted a criminal organization whose members and associates engaged in various related criminal activities’ across the 41… “The House Judiciary Committee is escalating its probe into Biden administration efforts to address disinformation, issuing subpoenas to Attorney General Merrick Garland and FBI Director Christopher Wray,” The Hill reports…. “The Fulton County sheriff’s department is investigating threats made against Georgia grand jurors who indicted former President Donald Trump for election interference,” Semafor reports. “The jurors’ personal information had been… Sen. Kyrsten Sinema (I-AZ) is calling on both the Biden administration and Sen. Tommy Tuberville (R-AL) to soften their positions and find a “middle ground” on a Pentagon policy involving… NBC News: “Tester has already ramped up his re-election bid by adding staffers across Montana and raising millions of dollars. While Democrats hope Tester’s deep connection to his home state… “President Joe Biden is using the presidential retreat at Camp David to help with a diplomatic mission – hosting the first-ever trilateral summit with Japan and South Korea, two countries… “Long among the most sensitive subjects inside the West Wing, Hunter Biden’s legal saga now appears destined to play out amid his father’s bid for reelection, frustrating the president but… “A Connecticut alderman and mayoral candidate is pressing ahead with his campaign after being charged this week by federal prosecutors with illegally entering the U.S. Capitol during the riot on… “A dual citizen of France and Canada who sent letters containing homemade ricin to then-President Donald Trump and eight Texas law enforcement officials was sentenced Thursday to nearly 22 years… “A group that works to elect Democrats as the top election officials in states around the country is planning a $10 million venture to pay for private security for election… “John Dean, the White House counsel to former President Nixon, predicted a grim fate for former New York City mayor and Trump ally Rudy Giuliani, who faces mounting legal fees… “Credit Suisse’s internal probe into allegations that it concealed information about accounts held by Nazis after World War II failed to review all available records, including some that may reveal… Donald Trump is upset that Fox News continues to use photos of him that make him look fat and orange. Write Trump on Truth Social: “Why doesn’t Fox and Friends… Jonathan Last: “It would not surprise me—at all—if Trump chooses to surrender himself on August 23. He’d then take over the entire news cycle that day with its wall-to-wall coverage… Members get exclusive analysis, a trending news page, bonus newsletters and no advertising. Learn more. Subscribe Taegan Goddard is the founder of Political Wire, one of the earliest and most influential political web sites. He also runs Political Job Hunt, Electoral Vote Map and the Political Dictionary. Goddard spent more than a decade as managing director and chief operating officer of a prominent investment firm in New York City. Previously, he was a policy adviser to a U.S. Senator and Governor. Goddard is also co-author of You Won - Now What? (Scribner, 1998), a political management book hailed by prominent journalists and politicians from both parties. In addition, Goddard's essays on politics and public policy have appeared in dozens of newspapers across the country. Goddard earned degrees from Vassar College and Harvard University. He lives in New York with his wife and three sons. Goddard is the owner of Goddard Media LLC. “There are a lot of blogs and news sites claiming to understand politics, but only a few actually do. Political Wire is one of them.” — Chuck Todd, host of “Meet the Press” “Concise. Relevant. To the point. Political Wire is the first site I check when I’m looking for the latest political nugget. That pretty much says it all.” — Stuart Rothenberg, editor of the Rothenberg Political Report “Political Wire is one of only four or five sites that I check every day and sometimes several times a day, for the latest political news and developments.” — Charlie Cook, editor of the Cook Political Report “The big news, delicious tidbits, pearls of wisdom — nicely packaged, constantly updated… What political junkie could ask for more?” — Larry Sabato, Center for Politics, University of Virginia “Political Wire is a great, great site.” — Joe Scarborough, host of MSNBC’s “Morning Joe” “Taegan Goddard has a knack for digging out political gems that too often get passed over by the mainstream press, and for delivering the latest electoral developments in a sharp, no frills style that makes his Political Wire an addictive blog habit you don’t want to kick.” — Arianna Huffington, founder of The Huffington Post “Political Wire is one of the absolute must-read sites in the blogosphere.” — Glenn Reynolds, founder of Instapundit “I rely on Taegan Goddard’s Political Wire for straight, fair political news, he gets right to the point. It’s an eagerly anticipated part of my news reading.” — Craig Newmark, founder of Craigslist. Copyright ©\\xa02023 · Goddard Media LLC | Privacy Policy Political Wire ® is a registered trademark of Goddard Media LLC\",\n",
       " 'hero': ['Robert Gates'],\n",
       " 'villain': [],\n",
       " 'victim': ['Barack Obama']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandRow(row, template):\n",
    "    \"\"\"\n",
    "    Generate prompts based on various roles and text chunks from the input row.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract values from the row\n",
    "    heros = row.get(\"hero\", [])\n",
    "    villains = row.get(\"villain\", [])\n",
    "    victims = row.get(\"victim\", [])\n",
    "\n",
    "    hero = heros[0] if len(heros) > 0 else \"no one\"\n",
    "    villain = villains[0] if len(villains) > 0 else \"no one\"\n",
    "    victim = victims[0] if len(victims) > 0 else \"no one\"\n",
    "\n",
    "    # Construct the prompt\n",
    "    prompt = template.format(hero=hero, villain=villain, victim=victim)\n",
    "\n",
    "    new_row = {\n",
    "        **row,\n",
    "        'prompt': prompt,\n",
    "    }\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Prompt: In this article Robert Gates is portrayed as a hero, no one is portrayed as a villain, and Barack Obama is portrayed as a victim.\n",
      "Expanded row: {'_id': '64d8eb39516b2658722931a5', 'title': 'Gates Says Obama Has Too Many &#8216;Yes Men&#8217;', 'url': 'https://politicalwire.com/2016/01/19/gates-says-obama-has-too-many-yes-men/', 'text': \" January 19, 2016 at 10:46 am EST By Taegan Goddard 25 Comments Former Defense Secretary Robert Gates suggested on MSNBC that President Obama has “centralized power and operational activities of the government in the White House to a degree that I think is unparalleled.” He added: “I don’t see the kind of strong people around the President who will push back on him. I will give him credit. I pushed back on him a lot and he never shut me down. He never told me to be quiet or refused to see me or anything like that. But I don’t see people around him like that now. “ Filed Under: Governing, White House Tagged With: Barack Obama, Robert Gates Donald Trump said on Truth Social that his lawyers would prefer that he didn’t have a Monday new conference to unveil his “irrefutable” evidence of fraud in the 2020 Georgia… “The current thinking among Donald Trump’s campaign advisers and those close to the former president is that he is not planning on participating in next week’s Republican presidential primary debate… “The U.S. intelligence community assesses that Ukraine’s counteroffensive will fail to reach the key southeastern city of Melitopol, a finding that, should it prove correct, would mean Kyiv won’t fulfill… “Lawyers for former President Donald Trump asked a judge on Thursday to reject the government’s proposal to take Mr. Trump to trial in early January on charges of seeking to… “North Korea’s successful test launch on July 12 of a nuclear-capable intercontinental ballistic missile equipped to penetrate U.S. missile defenses is likely the result of technical cooperation sourced to Russia,”… “We have been very lean and mean… we certainly don’t want to peak too soon.” — Miami Mayor Francis Suarez, on NBC News, on his apparent lack of any presidential… CNN: “The 98-page document alleges the 30 unindicted co-conspirators, who are not named, ‘constituted a criminal organization whose members and associates engaged in various related criminal activities’ across the 41… “The House Judiciary Committee is escalating its probe into Biden administration efforts to address disinformation, issuing subpoenas to Attorney General Merrick Garland and FBI Director Christopher Wray,” The Hill reports…. “The Fulton County sheriff’s department is investigating threats made against Georgia grand jurors who indicted former President Donald Trump for election interference,” Semafor reports. “The jurors’ personal information had been… Sen. Kyrsten Sinema (I-AZ) is calling on both the Biden administration and Sen. Tommy Tuberville (R-AL) to soften their positions and find a “middle ground” on a Pentagon policy involving… NBC News: “Tester has already ramped up his re-election bid by adding staffers across Montana and raising millions of dollars. While Democrats hope Tester’s deep connection to his home state… “President Joe Biden is using the presidential retreat at Camp David to help with a diplomatic mission – hosting the first-ever trilateral summit with Japan and South Korea, two countries… “Long among the most sensitive subjects inside the West Wing, Hunter Biden’s legal saga now appears destined to play out amid his father’s bid for reelection, frustrating the president but… “A Connecticut alderman and mayoral candidate is pressing ahead with his campaign after being charged this week by federal prosecutors with illegally entering the U.S. Capitol during the riot on… “A dual citizen of France and Canada who sent letters containing homemade ricin to then-President Donald Trump and eight Texas law enforcement officials was sentenced Thursday to nearly 22 years… “A group that works to elect Democrats as the top election officials in states around the country is planning a $10 million venture to pay for private security for election… “John Dean, the White House counsel to former President Nixon, predicted a grim fate for former New York City mayor and Trump ally Rudy Giuliani, who faces mounting legal fees… “Credit Suisse’s internal probe into allegations that it concealed information about accounts held by Nazis after World War II failed to review all available records, including some that may reveal… Donald Trump is upset that Fox News continues to use photos of him that make him look fat and orange. Write Trump on Truth Social: “Why doesn’t Fox and Friends… Jonathan Last: “It would not surprise me—at all—if Trump chooses to surrender himself on August 23. He’d then take over the entire news cycle that day with its wall-to-wall coverage… Members get exclusive analysis, a trending news page, bonus newsletters and no advertising. Learn more. Subscribe Taegan Goddard is the founder of Political Wire, one of the earliest and most influential political web sites. He also runs Political Job Hunt, Electoral Vote Map and the Political Dictionary. Goddard spent more than a decade as managing director and chief operating officer of a prominent investment firm in New York City. Previously, he was a policy adviser to a U.S. Senator and Governor. Goddard is also co-author of You Won - Now What? (Scribner, 1998), a political management book hailed by prominent journalists and politicians from both parties. In addition, Goddard's essays on politics and public policy have appeared in dozens of newspapers across the country. Goddard earned degrees from Vassar College and Harvard University. He lives in New York with his wife and three sons. Goddard is the owner of Goddard Media LLC. “There are a lot of blogs and news sites claiming to understand politics, but only a few actually do. Political Wire is one of them.” — Chuck Todd, host of “Meet the Press” “Concise. Relevant. To the point. Political Wire is the first site I check when I’m looking for the latest political nugget. That pretty much says it all.” — Stuart Rothenberg, editor of the Rothenberg Political Report “Political Wire is one of only four or five sites that I check every day and sometimes several times a day, for the latest political news and developments.” — Charlie Cook, editor of the Cook Political Report “The big news, delicious tidbits, pearls of wisdom — nicely packaged, constantly updated… What political junkie could ask for more?” — Larry Sabato, Center for Politics, University of Virginia “Political Wire is a great, great site.” — Joe Scarborough, host of MSNBC’s “Morning Joe” “Taegan Goddard has a knack for digging out political gems that too often get passed over by the mainstream press, and for delivering the latest electoral developments in a sharp, no frills style that makes his Political Wire an addictive blog habit you don’t want to kick.” — Arianna Huffington, founder of The Huffington Post “Political Wire is one of the absolute must-read sites in the blogosphere.” — Glenn Reynolds, founder of Instapundit “I rely on Taegan Goddard’s Political Wire for straight, fair political news, he gets right to the point. It’s an eagerly anticipated part of my news reading.” — Craig Newmark, founder of Craigslist. Copyright ©\\xa02023 · Goddard Media LLC | Privacy Policy Political Wire ® is a registered trademark of Goddard Media LLC\", 'hero': ['Robert Gates'], 'villain': [], 'victim': ['Barack Obama'], 'prompt': 'In this article Robert Gates is portrayed as a hero, no one is portrayed as a villain, and Barack Obama is portrayed as a victim.'}\n"
     ]
    }
   ],
   "source": [
    "example_row = articles[42]\n",
    "example_row_exp = expandRow(example_row, PROMPT_TEMPLATE)\n",
    "\n",
    "print(\"Example Prompt:\", example_row_exp.get(\"prompt\"))\n",
    "print(\"Expanded row:\", example_row_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process datataset using multiple proesses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this article {hero} is portrayed as a hero, {villain} is portrayed as a villain, and {victim} is portrayed as a victim.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing Prompts: 100%|██████████| 50/50 [00:00<00:00, 2954.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a progress bar with the total number of tasks\n",
    "pbar = tqdm(total=len(articles), desc=\"Constructing Prompts\",\n",
    "            position=0, leave=True)\n",
    "\n",
    "results = []\n",
    "for row in articles:\n",
    "        result = expandRow(row, PROMPT_TEMPLATE)\n",
    "        results.append(result)\n",
    "        pbar.update()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prompts: 50\n"
     ]
    }
   ],
   "source": [
    "dataset_hvv = results\n",
    "\n",
    "print(\"Number of prompts:\", len(dataset_hvv))\n",
    "\n",
    "# Convert the list of dictionaries into a Dataset\n",
    "dataset_hvv = Dataset.from_dict(\n",
    "    {key: [dic[key] for dic in dataset_hvv] for key in dataset_hvv[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 3534.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_hvv.save_to_disk('../data/input/articles_chunkified')\n",
    "dataset = dataset_hvv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "from datasets import Dataset, load_from_disk, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 50\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_disk('../data/input/articles_chunkified')\n",
    "print(\"Dataset length:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List infos about the available GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0:\n",
      "  Name: Tesla P100-PCIE-16GB\n",
      "  Memory: 16276.00 MiB\n",
      "  Compute Capability: 6.0\n",
      "\n",
      "GPU 1:\n",
      "  Name: Tesla P100-PCIE-16GB\n",
      "  Memory: 16276.00 MiB\n",
      "  Compute Capability: 6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info_list = listAvailableGPUs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the number of available GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "print(f'Number of available GPUs: {num_gpus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n",
      "Chunk 0 length: 25\n",
      "Chunk 1 length: 25\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into chunks (one for each GPU)\n",
    "chunks = splitDataset(dataset, num_chunks=num_gpus)\n",
    "\n",
    "# Print the length of each chunk\n",
    "print(\"Number of chunks:\", len(chunks))\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i} length:\", len(chunk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU utilization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 22 10:46:26 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    34W / 250W |    316MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:65:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    36W / 250W |    910MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1756034      C   ...nvs/mediacloud/bin/python      314MiB |\n",
      "|    1   N/A  N/A   1756034      C   ...nvs/mediacloud/bin/python      908MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for Text Generation\n",
    "\n",
    "Each parameter influences the text generation in a specific way. Below are the parameters along with a brief explanation:\n",
    "\n",
    "**`max_length`**:\n",
    "* Sets the maximum number of tokens in the generated text (default is 50).\n",
    "* Generation stops if the maximum length is reached before the model produces an EOS token.\n",
    "* A higher `max_length` allows for longer generated texts but may increase the time and computational resources required.\n",
    "\n",
    "**`min_length`**:\n",
    "* Sets the minimum number of tokens in the generated text (default is 10).\n",
    "* Generation continues until this minimum length is reached even if an EOS token is produced.\n",
    "\n",
    "**`num_beams`**:\n",
    "* In beam search, sets the number of \"beams\" or hypotheses to keep at each step (default is 4).\n",
    "* A higher number of beams increases the chances of finding a good output but also increases the computational cost.\n",
    "\n",
    "**`num_return_sequences`**:\n",
    "* Specifies the number of independently computed sequences to return (default is 3).\n",
    "* When using sampling, multiple different sequences are generated independently from each other.\n",
    "\n",
    "**`early_stopping`**:\n",
    "* Stops generation if the model produces the EOS (End Of Sentence) token, even if the predefined maximum length is not reached (default is True).\n",
    "* Useful when an EOS token signifies the logical end of a text (often represented as `</s>`).\n",
    "\n",
    "**`do_sample`**:\n",
    "* Tokens are selected probabilistically based on their likelihood scores (default is True).\n",
    "* Introduces randomness into the generation process for diverse outputs.\n",
    "* The level of randomness is controlled by the 'temperature' parameter.\n",
    "\n",
    "**`temperature`**:\n",
    "* Adjusts the probability distribution used for sampling the next token (default is 0.7).\n",
    "* Higher values make the generation more random, while lower values make it more deterministic.\n",
    "\n",
    "**`top_k`**:\n",
    "* Limits the number of tokens considered for sampling at each step to the top K most likely tokens (default is 50).\n",
    "* Can make the generation process faster and more focused.\n",
    "\n",
    "**`top_p`**:\n",
    "* Also known as nucleus sampling, sets a cumulative probability threshold (default is 0.95).\n",
    "* Tokens are sampled only from the smallest set whose cumulative probability exceeds this threshold.\n",
    "\n",
    "**`repetition_penalty`**:\n",
    "* Discourages the model from repeating the same token by modifying the token's score (default is 1.5).\n",
    "* Values greater than 1.0 penalize repetitions, and values less than 1.0 encourage repetitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePredictions(process_id, dataset, device):\n",
    "    \"\"\"Generates predictions for a given dataset.\"\"\"\n",
    "\n",
    "    # Print some information about the process\n",
    "    print(f\"--------- Process {process_id:02} ---------\")\n",
    "    print(f\"Dataset length: {len(dataset)}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"------------------------------\")\n",
    "\n",
    "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Device:\", torch.cuda.get_device_name())\n",
    "\n",
    "    dataset_full = copy.copy(dataset)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for row in tqdm(dataset_full, desc=\"Articles\"):\n",
    "            embedding = model.encode(row.get(\"prompt\"))\n",
    "            predictions.append(embedding)\n",
    "\n",
    "    # results.extend(predictions)\n",
    "\n",
    "    print(\"GPU finished:\", len(predictions))\n",
    "\n",
    "    #Ensure the new column has the same number of items as the dataset\n",
    "    assert len(dataset_full) == len(\n",
    "        predictions), \"The length of new_column_values must match the dataset's length\"\n",
    "\n",
    "    #print(\"Dataset length:\", len(dataset_full))\n",
    "\n",
    "    # Add new column\n",
    "    predictions_list = [tensor.tolist() for tensor in predictions]\n",
    "    dataset_full = dataset_full.add_column('answer', predictions_list)\n",
    "    dataset_full.save_to_disk('data/output/articles_processed_' + str(id))\n",
    "\n",
    "    return dataset_full\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start one thread per GPU before collecting and merging the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Process 00 ---------\n",
      "Dataset length: 25\n",
      "Device: cuda:0\n",
      "------------------------------\n",
      "--------- Process 01 ---------\n",
      "Dataset length: 25\n",
      "Device: cuda:1\n",
      "------------------------------\n",
      "Device: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Articles:   4%|▍         | 1/25 [00:00<00:08,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Articles: 100%|██████████| 25/25 [00:01<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU finished: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 25/25 [00:00<00:00, 2511.26 examples/s]\n",
      "Articles: 100%|██████████| 25/25 [00:00<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU finished: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 25/25 [00:00<00:00, 2880.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of returned datasets: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 2406.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing on both GPUs completed!\n",
      "Results: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming datasets and devices are lists containing the datasets and device names\n",
    "datasets = chunks  # and so on...\n",
    "devices = ['cuda:0', 'cuda:1']  # and so on...\n",
    "\n",
    "# Calls the function to start the threads\n",
    "returned_datasets = startThreads(len(datasets), datasets, devices, generatePredictions)\n",
    "print(\"Number of returned datasets:\", len(returned_datasets))\n",
    "\n",
    "# Concatenate the returned datasets\n",
    "merged_dataset = concatenate_datasets(returned_datasets)\n",
    "merged_dataset.save_to_disk('../data/output/articles_processed')\n",
    "\n",
    "# Print the length of the merged dataset\n",
    "print(\"Processing on both GPUs completed!\")\n",
    "print(\"Results:\", len(merged_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'title', 'url', 'text', 'hero', 'villain', 'victim', 'prompt', 'answer'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = merged_dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import *\n",
    "from utils.database import *\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 112\n",
      "Column names: ['_id', 'title', 'url', 'text', 'hero', 'villain', 'victim', 'prompt', 'role', 'entity', 'input_ids', 'attention_mask', 'entity_tokenized', 'answer']\n",
      "Features (schema): {'_id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'hero': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'villain': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'victim': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'prompt': Value(dtype='string', id=None), 'role': Value(dtype='string', id=None), 'entity': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'entity_tokenized': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'answer': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "del dataset\n",
    "dataset = load_from_disk('../data/output/articles_processed')\n",
    "describeDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: [-0.006319770589470863, 0.09470830112695694, 0.024422844871878624, 0.028843551874160767, -0.05869416147470474, 0.05381316319108009, 0.050233401358127594, -0.05282343551516533, -0.04206103831529617, -0.030477477237582207]\n"
     ]
    }
   ],
   "source": [
    "# Exmample amswer \n",
    "answer = dataset[0].get(\"answer\")\n",
    "print(\"Answer:\", answer[:10])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, db = getConnection(use_dotenv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Documents in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading results: 100%|██████████| 50/50 [00:00<00:00, 728.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(dataset, desc=\"Uploading results\"):\n",
    "    object_id = row.get(\"id\")\n",
    "    result = row.get(\"Answers\")\n",
    "    #updateProcessingResults(\n",
    "    #    db, object_id, {\"sentence_embedding_result\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediacloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
